{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02992cba-7164-4c9c-94e3-41bc45e9456e",
   "metadata": {},
   "source": [
    "# Example OCR model\n",
    "\n",
    "**This notebook is still experimental.** It will be updated in the next updates to give a concrete training example + documentation ;) Nevertheless, the available pretrained models seems to be accurate enough for a simple usage! Check the `ocr` notebook for more information and examples !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9ab6f2-5127-432a-b58e-8914353a25c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch # to avoid errors when converting the pre-trained weights\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle as sklearn_shuffle\n",
    "\n",
    "from loggers import set_level\n",
    "from utils import plot, plot_multiple\n",
    "from utils.image import load_image\n",
    "from models import get_pretrained\n",
    "from models.ocr import CRNN\n",
    "from datasets import get_dataset, train_test_split, prepare_dataset, test_dataset_time\n",
    "\n",
    "model_name = 'crnn_latin'\n",
    "print('Tensorflow version : {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a1024-e56d-4b52-9839-3378d4f6d4b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321de2d0-d770-4bcc-b490-c5385bfa8486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lang = model_name.split('_')[-1]\n",
    "\n",
    "model = CRNN(\n",
    "    nom  = model_name, lang = lang, pretrained_lang = lang\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(model.text_encoder)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0358a-2597-4243-a86a-171d30372703",
   "metadata": {},
   "source": [
    "## Model instanciation + dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1caf4-d563-448d-974c-f38b5d3bf505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_pretrained(model_name)\n",
    "\n",
    "lr = {'name' : 'DivideByStep', 'maxval' : 1e-3, 'minval' : 1e-4}\n",
    "\n",
    "model.compile(optimizer = 'adam', optimizer_config = {'lr' : lr})\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518eb8e9-a6be-4c8d-a73e-1c9345b1af66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = get_dataset('synthtext', one_line_per_box = True, add_image_size = False)\n",
    "\n",
    "if isinstance(dataset, dict):\n",
    "    train, valid = dataset['train'], dataset['valid']\n",
    "else:\n",
    "    train, valid = train_test_split(dataset, valid_size = 0.1, shuffle = True, random_state = 10)\n",
    "\n",
    "train = sklearn_shuffle(train, random_state = 10)\n",
    "    \n",
    "print('Dataset length :\\n  Train size : {}\\n  Valid size : {}'.format(len(train), len(valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68791b-b125-4243-92a4-dc4e077a1792",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645e0b7-bb4a-46ce-8420-924e564ecf56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs     = 5\n",
    "batch_size = 128\n",
    "\n",
    "augment_prct = 0.\n",
    "shuffle_size = batch_size * 8\n",
    "\n",
    "max_output_length = 64\n",
    "\n",
    "model.train(\n",
    "    train, validation_data = valid, epochs = epochs, batch_size = batch_size,\n",
    "    max_output_length = max_output_length,\n",
    "    augment_prct = augment_prct, shuffle_size = shuffle_size, cache = len(train) < 200000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b26b3-d853-4c17-b031-193a5c9bb390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.plot_history()\n",
    "print(model.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73d5ab-54e3-4bf2-a146-c3c2bccd3b07",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c463c-78ab-4076-8646-f918c3a3134c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = get_dataset('coco_text', modes = 'valid', one_line_per_box = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8c420-1906-4af9-8c38-9989774e82d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = valid\n",
    "\n",
    "for idx, row in samples.sample(10, random_state = 2).iterrows():\n",
    "    print(load_image(row['filename'], bbox = row['box']).shape)\n",
    "    print(model.get_input(row).shape)\n",
    "    inp = model.preprocess_input(tf.expand_dims(model.get_input(row), axis = 0))\n",
    "    plot(inp[0], plot_type = 'imshow')\n",
    "    print(inp.shape)\n",
    "    if tf.reduce_any(tf.shape(inp)[1:-1] < 16): continue\n",
    "    out = model.infer(inp, max_length = 10)\n",
    "    \n",
    "    print(row['label'], model.decode_output(out))\n",
    "    plot(inp[0], plot_type = 'imshow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90446d-c4ea-4f69-95d8-3c87f455c01e",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde0eab-640f-4040-a213-b28032e114fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_level('debug', 'datasets')\n",
    "\n",
    "config = model.get_dataset_config(is_validation = False, batch_size = 64, prefetch = False)\n",
    "\n",
    "train_ds = prepare_dataset(valid, ** config)\n",
    "\n",
    "set_level('info', 'datasets')\n",
    "\n",
    "test_dataset_time(train_ds, steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9ca64-d4ce-49f7-9cb0-c4f7144646e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
